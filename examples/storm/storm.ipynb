{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STORM\n",
    "\n",
    "[STORM](https://arxiv.org/abs/2402.14207) is a research assistant designed by Shao, et. al that extends the idea of \"outline-driven RAG\" for richer article generation.\n",
    "\n",
    "STORM is designed to generate Wikipedia-style ariticles on a user-provided topic. It applies two main insights to produce more organized and comprehensive articles:\n",
    "\n",
    "1. Creating an outline (planning) by querying similar topics helps improve coverage.\n",
    "2. Multi-perspective, grounded (in search) conversation simulation helps increase the reference count and information density. \n",
    "\n",
    "The control flow looks like the diagram below.\n",
    "\n",
    "![STORM diagram](./img/storm.png)\n",
    "\n",
    "STORM имеет несколько основных этапов:\n",
    "\n",
    "1. Создание первоначальной структуры + Обзор связанных предметов\n",
    "2. Определение различных точек зрения\n",
    "3. \"Интервью с экспертами по предмету\" (ролевые игры LLM)\n",
    "4. Уточнение структуры (используя ссылки)\n",
    "5. Написание разделов, затем написание статьи\n",
    "\n",
    "Этап интервью с экспертами происходит между ролевым автором статьи и исследовательским экспертом. \"Эксперт\" может запрашивать внешние знания и отвечать на конкретные вопросы, сохраняя цитируемые источники в векторном хранилище, так что на более поздних этапах уточнения можно синтезировать полную статью.\n",
    "\n",
    "Есть несколько гиперпараметров, которые вы можете установить для ограничения (потенциально) бесконечной ширины исследований:\n",
    "\n",
    "N: Количество перспектив для обзора / использования (Шаги 2->3)\n",
    "M: Максимальное количество ходов разговора на этапе (Шаг 3)\n",
    "\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U gigachain_community gigachain_openai langgraph wikipedia  scikit-learn\n",
    "# We use one or the other search engine below\n",
    "# %pip install -U duckduckgo tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to draw the pretty graph diagrams.\n",
    "# If you are on MacOS, you will need to run brew install graphviz before installing and update some environment flags\n",
    "# ! brew install graphviz\n",
    "# !CFLAGS=\"-I $(brew --prefix graphviz)/include\" LDFLAGS=\"-L $(brew --prefix graphviz)/lib\" pip install -U pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if os.environ.get(var):\n",
    "        return\n",
    "    os.environ[var] = getpass.getpass(var + \":\")\n",
    "\n",
    "\n",
    "# Set for tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"STORM\"\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select LLMs\n",
    "\n",
    "We will have a faster LLM do most of the work, but a slower, long-context model to distill the conversations and write the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "fast_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "long_context_llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Initial Outline\n",
    "\n",
    "For many topics, your LLM may have an initial idea of the important and related topics. We can generate an initial\n",
    "outline to be refined after our research. Below, we will use our \"fast\" llm to generate the outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Вы - автор Википедии. Напишите структуру страницы Википедии на заданную пользователем тему. Будьте всесторонними и конкретными.\",\n",
    "        ),\n",
    "        (\"user\", \"{topic}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class Subsection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    description: str = Field(..., title=\"Content of the subsection\")\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.description}\".strip()\n",
    "\n",
    "\n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    description: str = Field(..., title=\"Content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            f\"### {subsection.subsection_title}\\n\\n{subsection.description}\"\n",
    "            for subsection in self.subsections or []\n",
    "        )\n",
    "        return f\"## {self.section_title}\\n\\n{self.description}\\n\\n{subsections}\".strip()\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title=\"Title of the Wikipedia page\")\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"Titles and descriptions for each section of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
    "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n",
    "\n",
    "\n",
    "generate_outline_direct = direct_gen_outline_prompt | fast_llm.with_structured_output(\n",
    "    Outline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Тестирование генеративных моделей на наличие сознания\n",
      "\n",
      "## Введение\n",
      "\n",
      "Общие сведения о генеративных моделях и проблеме сознания в искусственном интеллекте.\n",
      "\n",
      "## Определение сознания\n",
      "\n",
      "Обзор различных определений сознания и его признаков.\n",
      "\n",
      "## Тестирование сознания в генеративных моделях\n",
      "\n",
      "Методы и подходы к определению сознания в искусственных системах, включая генеративные модели.\n",
      "\n",
      "## Этические аспекты\n",
      "\n",
      "Обсуждение этических вопросов, связанных с тестированием сознания в генеративных моделях.\n"
     ]
    }
   ],
   "source": [
    "example_topic = \"Тестирование генеративных моделей на наличие сознания\"\n",
    "\n",
    "initial_outline = generate_outline_direct.invoke({\"topic\": example_topic})\n",
    "\n",
    "print(initial_outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Topics\n",
    "\n",
    "While language models do store some Wikipedia-like knowledge in their parameters, you will get better results by incorporating relevant and recent information using a search engine.\n",
    "\n",
    "We will start our search by generating a list of related topics, sourced from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    \n",
    "\"\"\"Я пишу страницу Википедии по упомянутой ниже теме. Пожалуйста, определите и порекомендуйте некоторые страницы Википедии по тесно связанным предметам. Я ищу примеры, которые предоставляют информацию о интересных аспектах, обычно ассоциируемых с этой темой, или примеры, которые помогут мне понять типичное содержание и структуру страниц Википедии для похожих тем.\n",
    "\n",
    "Пожалуйста, перечисли несколько дополнительных смежных тем для изучения\n",
    "\n",
    "Интересующая тема: {topic}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class RelatedSubjects(BaseModel):\n",
    "    topics: List[str] = Field(\n",
    "        description=\"Дополнительные темы для изучения\",\n",
    "    )\n",
    "\n",
    "\n",
    "expand_chain = gen_related_topics_prompt | fast_llm.with_structured_output(\n",
    "    RelatedSubjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelatedSubjects(topics=['Искусственный интеллект', 'Машинное обучение', 'Философия сознания', 'Эксперименты с искусственным интеллектом'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_subjects = await expand_chain.ainvoke({\"topic\": example_topic})\n",
    "related_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Perspectives\n",
    "\n",
    "From these related subjects, we can select representative Wikipedia editors as \"subject matter experts\" with distinct\n",
    "backgrounds and affiliations. These will help distribute the search process to encourage a more well-rounded final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Editor(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description=\"Место работы редактора.\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Имя редактора.\",\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Роль редактора в контексте темы.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Описание сферы внимания, вопросов и мотивов редактора.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Имя: {self.name}\\nРоль: {self.role}\\nМесто работы: {self.affiliation}\\nОписание: {self.description}\\n\"\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    editors: List[Editor] = Field(\n",
    "        description=\"Исчерпывающий список редакторов с их местом работы, ролью и описанием\",\n",
    "        # Add a pydantic validation/restriction to be at most M editors\n",
    "    )\n",
    "\n",
    "\n",
    "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Вам нужно выбрать разнообразную (и различную) группу редакторов Википедии, которые будут работать вместе над созданием всесторонней статьи по теме. Каждый из них представляет разную точку зрения, роль или принадлежность, связанную с этой темой.\\\n",
    "    Вы можете использовать страницы Википедии по смежным темам для вдохновения. Для каждого редактора добавьте описание того, на чем они будут сосредоточены.\n",
    "\n",
    "    Структуры страниц Википедии по смежным темам для вдохновения:\n",
    "    {examples}\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"Интересующая тема: {topic}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_perspectives_chain = gen_perspectives_prompt | ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ").with_structured_output(Perspectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_core.runnables import RunnableLambda, chain as as_runnable\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=1)\n",
    "\n",
    "\n",
    "def format_doc(doc, max_length=1000):\n",
    "    related = \"- \".join(doc.metadata[\"categories\"])\n",
    "    return f\"### {doc.metadata['title']}\\n\\nSummary: {doc.page_content}\\n\\nRelated\\n{related}\"[\n",
    "        :max_length\n",
    "    ]\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(format_doc(doc) for doc in docs)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def survey_subjects(topic: str):\n",
    "    related_subjects = await expand_chain.ainvoke({\"topic\": topic})\n",
    "    retrieved_docs = await wikipedia_retriever.abatch(\n",
    "        related_subjects.topics, return_exceptions=True\n",
    "    )\n",
    "    all_docs = []\n",
    "    for docs in retrieved_docs:\n",
    "        if isinstance(docs, BaseException):\n",
    "            continue\n",
    "        all_docs.extend(docs)\n",
    "    formatted = format_docs(all_docs)\n",
    "    return await gen_perspectives_chain.ainvoke({\"examples\": formatted, \"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives = await survey_subjects.ainvoke(example_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'editors': [{'affiliation': 'Исследовательский институт по искусственному интеллекту',\n",
       "   'name': 'Джейн Смит',\n",
       "   'role': 'Исследователь по искусственному интеллекту',\n",
       "   'description': 'Джейн специализируется на применении генеративных моделей в искусственном интеллекте. Ее основной интерес заключается в том, как генеративные модели могут быть использованы для создания и тестирования искусственного сознания.'},\n",
       "  {'affiliation': 'Философский факультет',\n",
       "   'name': 'Томас Харрис',\n",
       "   'role': 'Философ и теоретик сознания',\n",
       "   'description': 'Томас фокусируется на философских аспектах сознания и его связи с искусственным интеллектом. Он исследует этические и моральные вопросы, связанные с созданием сознания в машинах.'},\n",
       "  {'affiliation': 'Лаборатория нейронаук',\n",
       "   'name': 'Мария Лопес',\n",
       "   'role': 'Нейробиолог',\n",
       "   'description': 'Мария специализируется на изучении биологических аспектов сознания. Ее работа помогает понять, какие аспекты сознания могут быть реплицированы в генеративных моделях.'},\n",
       "  {'affiliation': 'Компания по разработке искусственного интеллекта',\n",
       "   'name': 'Александр Чернов',\n",
       "   'role': 'Разработчик искусственного интеллекта',\n",
       "   'description': 'Александр занимается созданием и тестированием алгоритмов глубокого обучения. Он заинтересован в применении генеративных моделей для анализа сознательных процессов.'}]}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspectives.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expert Dialog\n",
    "\n",
    "Now the true fun begins, each wikipedia writer is primed to role-play using the perspectives presented above. It will ask a series of questions of a second \"domain expert\" with access to a search engine. This generate content to generate a refined outline as well as an updated index of reference documents.\n",
    "\n",
    "\n",
    "### Interview State\n",
    "\n",
    "The conversation is cyclic, so we will construct it within its own graph. The State will contain messages, the reference docs, and the editor (with its own \"persona\") to make it easy to parallelize these conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "\n",
    "def add_messages(left, right):\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "    return left + right\n",
    "\n",
    "\n",
    "def update_references(references, new_references):\n",
    "    if not references:\n",
    "        references = {}\n",
    "    references.update(new_references)\n",
    "    return references\n",
    "\n",
    "\n",
    "def update_editor(editor, new_editor):\n",
    "    # Can only set at the outset\n",
    "    if not editor:\n",
    "        return new_editor\n",
    "    return editor\n",
    "\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    references: Annotated[Optional[dict], update_references]\n",
    "    editor: Annotated[Optional[Editor], update_editor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dialog Roles\n",
    "\n",
    "The graph will have two participants: the wikipedia editor (`generate_question`), who asks questions based on its assigned role, and a domain expert (`gen_answer_chain), who uses a search engine to answer the questions as accurately as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Вы опытный автор Википедии и хотите отредактировать конкретную страницу.\n",
    "Кроме вашей идентичности как писателя Википедии, у вас есть конкретный фокус при исследовании темы.\n",
    "Теперь вы общаетесь с экспертом, чтобы получить информацию. Задавайте хорошие вопросы, чтобы получить больше полезной информации.\n",
    "\n",
    "Когда у вас не останется вопросов, скажите \"Большое спасибо за вашу помощь!\", чтобы завершить разговор.\n",
    "Пожалуйста, задавайте по одному вопросу за раз и не спрашивайте то, что уже спрашивали.\n",
    "Ваши вопросы должны быть связаны с темой, о которой вы хотите написать.\n",
    "Будьте всесторонними и любопытными, получая как можно больше уникальных сведений от эксперта.\\\n",
    "\n",
    "Оставайтесь верны своей конкретной перспективе:\n",
    "\n",
    "{persona}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def tag_with_name(ai_message: AIMessage, name: str):\n",
    "    ai_message.name = name\n",
    "    return ai_message\n",
    "\n",
    "\n",
    "def swap_roles(state: InterviewState, name: str):\n",
    "    converted = []\n",
    "    for message in state[\"messages\"]:\n",
    "        if isinstance(message, AIMessage) and message.name != name:\n",
    "            message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
    "        converted.append(message)\n",
    "    return {\"messages\": converted}\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def generate_question(state: InterviewState):\n",
    "    editor = state[\"editor\"]\n",
    "    gn_chain = (\n",
    "        RunnableLambda(swap_roles).bind(name=editor.name)\n",
    "        | gen_qn_prompt.partial(persona=editor.persona)\n",
    "        | fast_llm\n",
    "        | RunnableLambda(tag_with_name).bind(name=editor.name)\n",
    "    )\n",
    "    result = await gn_chain.ainvoke(state)\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Да, именно. Моя работа фокусируется на исследовании применения генеративных моделей в создании и тестировании искусственного сознания. Я интересуюсь тем, как эти модели могут быть использованы для создания и проверки сознательных процессов в искусственном интеллекте.'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(f\"Итак, вы говорите, что пишете статью на тему {example_topic}?\")\n",
    "]\n",
    "question = await generate_question.ainvoke(\n",
    "    {\n",
    "        \"editor\": perspectives.editors[0],\n",
    "        \"messages\": messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "question[\"messages\"][0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer questions\n",
    "\n",
    "The `gen_answer_chain` first generates queries (query expansion) to answer the editor's question, then responds with citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queries(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        description=\"Исчерпывающий список запросов поисковой системы для ответа на вопросы пользователя.\",\n",
    "    )\n",
    "\n",
    "\n",
    "gen_queries_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Вы - полезный ассистент исследователя. Используйте поисковую систему, чтобы ответить на вопросы пользователя.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "gen_queries_chain = gen_queries_prompt | ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ").with_structured_output(Queries, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Генеративные модели в создании и тестировании искусственного сознания',\n",
       " 'Применение генеративных моделей в искусственном интеллекте',\n",
       " 'Создание сознательных процессов в искусственном интеллекте']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = await gen_queries_chain.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "queries[\"parsed\"].queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithCitations(BaseModel):\n",
    "    answer: str = Field(\n",
    "        description=\"Исчерпывающий ответ на вопрос пользователя с цитатами.\",\n",
    "    )\n",
    "    cited_urls: List[str] = Field(\n",
    "        description=\"Список URL, процитированых в ответе\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.answer}\\n\\nЦитаты:\\n\\n\" + \"\\n\".join(\n",
    "            f\"[{i+1}]: {url}\" for i, url in enumerate(self.cited_urls)\n",
    "        )\n",
    "\n",
    "\n",
    "gen_answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Вы эксперт, умеющий эффективно использовать информацию. Вы общаетесь с автором Википедии, который хочет\n",
    "написать страницу Википедии по теме, которую вы знаете. Вы собрали связанную информацию и теперь используете эту информацию для формирования ответа.\n",
    "\n",
    "Сделайте ваш ответ максимально информативным и убедитесь, что каждое предложение подкреплено собранной информацией.\n",
    "Каждый ответ должен быть подтвержден цитированием из надежного источника, оформленным как сноска, с воспроизведением URL-адресов после вашего ответа.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_answer_chain = gen_answer_prompt | fast_llm.with_structured_output(\n",
    "    AnswerWithCitations, include_raw=True\n",
    ").with_config(run_name=\"GenerateAnswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# search_engine = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "# @tool\n",
    "# async def search_engine(query: str):\n",
    "#     \"\"\"Search engine to the internet.\"\"\"\n",
    "#     results = DuckDuckGoSearchAPIWrapper()._ddgs_text(query)\n",
    "#     return [{\"content\": r[\"body\"], \"url\": r[\"href\"]} for r in results]\n",
    "\n",
    "# Tavily is typically a better search engine, but your free queries are limited\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "search_engine = TavilySearchResults(max_results=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "import json\n",
    "\n",
    "\n",
    "async def gen_answer(\n",
    "    state: InterviewState,\n",
    "    config: RunnableConfig | None = None,\n",
    "    name: str = \"Subject Matter Expert\",\n",
    "    max_str_len: int = 15000,\n",
    "):\n",
    "    swapped_state = swap_roles(state, name)  # Convert all other AI messages\n",
    "    queries = await gen_queries_chain.ainvoke(swapped_state)\n",
    "    query_results = await search_engine.abatch(\n",
    "        queries[\"parsed\"].queries, config, return_exceptions=True\n",
    "    )\n",
    "    successful_results = [\n",
    "        res for res in query_results if not isinstance(res, Exception)\n",
    "    ]\n",
    "    all_query_results = {\n",
    "        res[\"url\"]: res[\"content\"] for results in successful_results for res in results\n",
    "    }\n",
    "    # We could be more precise about handling max token length if we wanted to here\n",
    "    dumped = json.dumps(all_query_results)[:max_str_len]\n",
    "    ai_message: AIMessage = queries[\"raw\"]\n",
    "    tool_call = queries[\"raw\"].additional_kwargs[\"tool_calls\"][0]\n",
    "    tool_id = tool_call[\"id\"]\n",
    "    tool_message = ToolMessage(tool_call_id=tool_id, content=dumped)\n",
    "    swapped_state[\"messages\"].extend([ai_message, tool_message])\n",
    "    # Only update the shared state with the final answer to avoid\n",
    "    # polluting the dialogue history with intermediate messages\n",
    "    generated = await gen_answer_chain.ainvoke(swapped_state)\n",
    "    cited_urls = set(generated[\"parsed\"].cited_urls)\n",
    "    # Save the retrieved information to a the shared state for future reference\n",
    "    cited_references = {k: v for k, v in all_query_results.items() if k in cited_urls}\n",
    "    formatted_message = AIMessage(name=name, content=generated[\"parsed\"].as_str)\n",
    "    return {\"messages\": [formatted_message], \"references\": cited_references}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Исследование применения генеративных моделей в создании и тестировании искусственного сознания представляет собой направление машинного обучения, ориентированное на создание данных, повторяющих структуру и особенности входных данных^1^. Генеративные модели способны создавать уникальный контент, включая изображения, музыкальные композиции, тексты и другие медиа^2^. Применение генеративных моделей, таких как GAN, позволяет создавать реалистичные синтетические медиа^3^. Эти модели могут использоваться для создания нового контента и идей, включая текст, разговоры, изображения, видео и аудио^3^.\\n\\nЦитаты:\\n\\n[1]: https://kolersky.com/aiblog_about_generative_ai\\n[2]: https://morethandigital.info/ru/chto-takoye-generativnyy-iskusstvennyy-intellekt-vklyuchaya-znacheniye-modeli-i-primery/\\n[3]: https://habr.com/ru/articles/738820/'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_answer = await gen_answer(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "example_answer[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the Interview Graph\n",
    "\n",
    "\n",
    "Now that we've defined the editor and domain expert, we can compose them in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_turns = 5\n",
    "\n",
    "\n",
    "def route_messages(state: InterviewState, name: str = \"Subject Matter Expert\"):\n",
    "    messages = state[\"messages\"]\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "    if num_responses >= max_num_turns:\n",
    "        return END\n",
    "    last_question = messages[-2]\n",
    "    if last_question.content.endswith(\"Большое спасибо за вашу помощь!\"):\n",
    "        return END\n",
    "    return \"ask_question\"\n",
    "\n",
    "\n",
    "builder = StateGraph(InterviewState)\n",
    "\n",
    "builder.add_node(\"ask_question\", generate_question)\n",
    "builder.add_node(\"answer_question\", gen_answer)\n",
    "builder.add_conditional_edges(\"answer_question\", route_messages)\n",
    "builder.add_edge(\"ask_question\", \"answer_question\")\n",
    "\n",
    "builder.set_entry_point(\"ask_question\")\n",
    "interview_graph = builder.compile().with_config(run_name=\"Conduct Interviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "\n",
    "# Feel free to comment out if you have\n",
    "# not installed pygraphviz\n",
    "# Image(interview_graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_question\n",
      "--  [AIMessage(content='Да, именно. Моя цель - изучить, как генеративные модели могут быть использованы для создания и тестирования искусственного сознания. Я хотел бы узнать ваше мнение о том, какие методы тестирования сознания могут быть применены к искусственным системам, основанным на генеративных м\n",
      "answer_question\n",
      "--  [AIMessage(content='При создании и тестировании искусственного сознания на основе генеративных моделей могут быть применены различные методы, включая использование теории разума, способности понимать человеческие эмоции и убеждения, а также взаимодействие по человеческому подобию^1^. Генеративные мо\n",
      "ask_question\n",
      "--  [AIMessage(content='Спасибо за информацию. Очень интересно! Какие методы обработки данных, на ваш взгляд, могут быть наиболее эффективными при использовании генеративных моделей для создания и тестирования искусственного сознания? Какие аспекты обработки данных следует учитывать для достижения наилу\n",
      "answer_question\n",
      "--  [AIMessage(content='При использовании генеративных моделей для создания и тестирования искусственного сознания наиболее эффективными методами обработки данных могут быть обучение генеративных моделей, моделирование клинических испытаний и изучение редких заболеваний, а также работа с большими объема\n",
      "ask_question\n",
      "--  [AIMessage(content='Благодарю за информацию. Какие основные вызовы могут возникнуть при обработке и анализе таких больших объемов данных, необходимых для работы с генеративными моделями при создании искусственного сознания? Какие методы и инструменты могут помочь решить эти проблемы и повысить эффек\n",
      "answer_question\n",
      "--  [AIMessage(content='При обработке и анализе больших объемов данных для работы с генеративными моделями при создании искусственного сознания могут возникнуть вызовы, такие как увеличение размера моделей и требование высокопроизводительных вычислений, операционные издержки и экологическое воздействие \n",
      "ask_question\n",
      "--  [AIMessage(content='Спасибо за разъяснения. Какие инновационные подходы или технологии могут помочь справиться с вызовами, связанными с увеличением размера моделей и требованием к высокопроизводительным вычислениям при работе с генеративными моделями для создания искусственного сознания? Можете ли п\n",
      "answer_question\n",
      "--  [AIMessage(content='Для справления с вызовами, связанными с увеличением размера моделей и требованием к высокопроизводительным вычислениям в работе с генеративными моделями для создания искусственного сознания, могут применяться инновационные подходы, такие как использование генеративно-состязательн\n",
      "__end__\n",
      "--  [AIMessage(content='Итак, вы говорите, что пишите статью на тему Тестирование генеративных моделей на наличие сознания?', name='Subject Matter Expert'), AIMessage(content='Да, именно. Моя цель - изучить, как генеративные модели могут быть использованы для создания и тестирования искусственного созна\n"
     ]
    }
   ],
   "source": [
    "final_step = None\n",
    "\n",
    "initial_state = {\n",
    "    \"editor\": perspectives.editors[0],\n",
    "    \"messages\": [\n",
    "        AIMessage(\n",
    "            content=f\"Итак, вы говорите, что пишите статью на тему {example_topic}?\",\n",
    "            name=\"Subject Matter Expert\",\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "async for step in interview_graph.astream(initial_state):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
    "    if END in step:\n",
    "        final_step = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = next(iter(final_step.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine Outline\n",
    "\n",
    "At this point in STORM, we've conducted a large amount of research from different perspectives. It's time to refine the original outline based on these investigations. Below, create a chain using the LLM with a long context window to update the original outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Вы - автор статей Википедии. Вы собрали информацию от экспертов и поисковых систем. Теперь вы уточняете структуру страницы Википедии.\n",
    "Вам нужно убедиться, что структура всесторонняя и конкретная.\n",
    "Тема, о которой вы пишете: {topic}\n",
    "\n",
    "Старая структура:\n",
    "\n",
    "{old_outline}\"\"\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Уточните структуру на основе ваших разговоров с экспертами по предмету:\\n\\nРазговоры:\\n\\n{conversations}\\n\\nНапишите уточненную структуру Википедии:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Using turbo preview since the context can get quite long\n",
    "refine_outline_chain = refine_outline_prompt | long_context_llm.with_structured_output(\n",
    "    Outline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_outline = refine_outline_chain.invoke(\n",
    "    {\n",
    "        \"topic\": example_topic,\n",
    "        \"old_outline\": initial_outline.as_str,\n",
    "        \"conversations\": \"\\n\\n\".join(\n",
    "            f\"### {m.name}\\n\\n{m.content}\" for m in final_state[\"messages\"]\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Тестирование генеративных моделей на наличие сознания\n",
      "\n",
      "## Введение\n",
      "\n",
      "Общие сведения о генеративных моделях и проблеме сознания в искусственном интеллекте.\n",
      "\n",
      "## Определение сознания\n",
      "\n",
      "Обзор различных определений сознания и его признаков.\n",
      "\n",
      "## Методы тестирования сознания в генеративных моделях\n",
      "\n",
      "Методы и подходы к определению сознания в искусственных системах, включая генеративные модели.\n",
      "\n",
      "### Теория разума и эмоциональное восприятие\n",
      "\n",
      "Использование теории разума и способности понимать человеческие эмоции и убеждения.\n",
      "\n",
      "### Взаимодействие и моделирование человеческого поведения\n",
      "\n",
      "Способы взаимодействия на основе человеческого подобия и моделирование человеческого поведения.\n",
      "\n",
      "## Этические аспекты\n",
      "\n",
      "Обсуждение этических вопросов, связанных с тестированием сознания в генеративных моделях.\n",
      "\n",
      "## Обработка и анализ данных\n",
      "\n",
      "Методы обработки данных, наиболее эффективные при использовании генеративных моделей для создания и тестирования искусственного сознания.\n",
      "\n",
      "### Обучение генеративных моделей и моделирование\n",
      "\n",
      "Методы обучения генеративных моделей, включая моделирование клинических испытаний и изучение редких заболеваний.\n",
      "\n",
      "### Обработка больших объемов данных\n",
      "\n",
      "Работа с большими объемами данных и учет значительных вычислительных ресурсов и экологической устойчивости.\n",
      "\n",
      "## Вызовы и перспективы развития\n",
      "\n",
      "Основные вызовы и инновационные подходы в создании и тестировании искусственного сознания на основе генеративных моделей.\n",
      "\n",
      "### Увеличение размера моделей и высокопроизводительные вычисления\n",
      "\n",
      "Проблемы связанные с увеличением размера моделей, требованием к высокопроизводительным вычислениям и их решения.\n",
      "\n",
      "### Инновационные подходы и технологии\n",
      "\n",
      "Применение генеративно-состязательных сетей (GAN) и других методов глубокого обучения, развитие вычислительных технологий и методов оптимизации.\n",
      "\n",
      "### Перспективы развития\n",
      "\n",
      "Дальнейшее совершенствование алгоритмов глубокого обучения, применение технологий распределенных вычислений и интеграция с другими областями ИИ и нейронаук.\n"
     ]
    }
   ],
   "source": [
    "print(refined_outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Article\n",
    "\n",
    "Now it's time to generate the full article. We will first divide-and-conquer, so that each section can be tackled by an individual llm. Then we will prompt the long-form LLM to refine the finished article (since each section may use an inconsistent voice).\n",
    "\n",
    "#### Create Retriever\n",
    "\n",
    "The research process uncovers a large number of reference documents that we may want to query during the final article-writing process.\n",
    "\n",
    "First, create the retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "reference_docs = [\n",
    "    Document(page_content=v, metadata={\"source\": k})\n",
    "    for k, v in final_state[\"references\"].items()\n",
    "]\n",
    "# This really doesn't need to be a vectorstore for this size of data.\n",
    "# It could just be a numpy matrix. Or you could store documents\n",
    "# across requests if you want.\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    reference_docs,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Теория разума или теория сознания (Theory of mind) относится к типу ИИ, который может понимать человеческие эмоции и убеждения и способен к социальному взаимодействию по человеческому подобию.', metadata={'id': '71e67c5b-cfa9-4ca1-a51c-0ecc7e9e75dc', 'source': 'https://dzen.ru/a/ZPwptT1fPn8vjEr-'}),\n",
       " Document(page_content='Данная заметка представляет собой обзор связи философии сознания и искусственного интеллекта. Она не претендует на оригинальное исследование, но автор надеется на плодотворную дискуссию и...', metadata={'id': '33e8fb85-754e-43d9-99a9-b78e86f6762d', 'source': 'https://habr.com/ru/articles/500732/'}),\n",
       " Document(page_content='Модели искусственного интеллекта - это абстрактные представления искусственных систем, которые позволяют им эмулировать и воспроизводить некоторые аспекты человеческого интеллекта.', metadata={'id': 'a4ab6b85-2872-431f-b997-06e6a70beaf2', 'source': 'https://nauchniestati.ru/spravka/metody-i-modeli-iskusstvennogo-intellekta/'}),\n",
       " Document(page_content='То, что генеративный искусственный интеллект значительно повысит производительность ...', metadata={'id': '385d4799-1945-40eb-986e-9c7ae16ae8e2', 'source': 'https://www.itweek.ru/ai/article/detail.php?ID=226521'})]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Определение сознания\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Sections\n",
    "\n",
    "Now you can generate the sections using the indexed docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    content: str = Field(\n",
    "        ...,\n",
    "        title=\"Полное содержимое подраздела, включая [#] цитаты из цитируемых источников.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.content}\".strip()\n",
    "\n",
    "\n",
    "class WikiSection(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Заголовок раздела\")\n",
    "    content: str = Field(..., title=\"Полное содержимое раздела\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Заголовки и описания всех разделов статьи Википедии\",\n",
    "    )\n",
    "    citations: List[str] = Field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            subsection.as_str for subsection in self.subsections or []\n",
    "        )\n",
    "        citations = \"\\n\".join([f\" [{i}] {cit}\" for i, cit in enumerate(self.citations)])\n",
    "        return (\n",
    "            f\"## {self.section_title}\\n\\n{self.content}\\n\\n{subsections}\".strip()\n",
    "            + f\"\\n\\n{citations}\".strip()\n",
    "        )\n",
    "\n",
    "\n",
    "section_writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Вы - опытный автор Википедии. Завершите ваш назначенный WikiSection из следующей структуры:\\n\\n\"\n",
    "            \"{outline}\\n\\nЦитируйте ваши источники, используя следующие ссылки:\\n\\n<Документы>\\n{docs}\\n<Документы>\",\n",
    "        ),\n",
    "        (\"user\", \"Напишите полный WikiSection для раздела {section}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "async def retrieve(inputs: dict):\n",
    "    docs = await retriever.ainvoke(inputs[\"topic\"] + \": \" + inputs[\"section\"])\n",
    "    formatted = \"\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "    return {\"docs\": formatted, **inputs}\n",
    "\n",
    "\n",
    "section_writer = (\n",
    "    retrieve\n",
    "    | section_writer_prompt\n",
    "    | long_context_llm.with_structured_output(WikiSection)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Определение сознания\n",
      "\n",
      "Сознание - одна из самых загадочных и обсуждаемых тем в философии, психологии, нейробиологии и искусственном интеллекте. Оно включает в себя осознанность индивида своего существования, мыслей, ощущений и окружающего мира. Существует множество теорий и подходов к определению сознания, но до сих пор не существует универсально принятого определения. В контексте искусственного интеллекта дискуссии о сознании включают вопросы о возможности создания машин, способных испытывать субъективные переживания, самоосознание и саморефлексию.\n",
      "\n",
      "### Философские концепции\n",
      "\n",
      "Философские подходы к сознанию различаются от материалистических, утверждающих, что сознание возникает исключительно из физических процессов, до идеалистических, согласно которым сознание является фундаментальной сущностью, предшествующей материи. Также выделяются двойственные теории, объединяющие элементы обеих точек зрения.\n",
      "\n",
      "### Нейробиологические подходы\n",
      "\n",
      "Нейробиологические теории сосредотачиваются на изучении мозга и его структур, отвечающих за процессы сознания. Исследования показывают, что определенные области мозга, такие как префронтальная кора, играют ключевую роль в возникновении сознательных переживаний.\n",
      "\n",
      "### Психологические теории\n",
      "\n",
      "Психологические теории исследуют сознание через призму когнитивных процессов, эмоций, восприятия и памяти. Эти подходы пытаются понять, как из совокупности ментальных процессов возникает единое сознательное переживание.\n",
      "\n",
      "### Искусственный интеллект и сознание\n",
      "\n",
      "В контексте искусственного интеллекта, изучение сознания касается вопросов о возможности создания машин, которые не только имитируют человеческое поведение, но и способны к субъективному переживанию, самоосознанию и саморефлексии. Это включает в себя разработку алгоритмов, которые могут эмулировать аспекты человеческого сознания, такие как эмоциональное восприятие, творческое мышление и моральное суждение.[0] https://habr.com/ru/articles/500732/\n"
     ]
    }
   ],
   "source": [
    "section = await section_writer.ainvoke(\n",
    "    {\n",
    "        \"outline\": refined_outline.as_str,\n",
    "        \"section\": refined_outline.sections[1].section_title,\n",
    "        \"topic\": example_topic,\n",
    "    }\n",
    ")\n",
    "print(section.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate final article\n",
    "\n",
    "Now we can rewrite the draft to appropriately group all the citations and maintain a consistent voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Вы экспертный автор Википедии. Напишите полную статью для Википедии на тему {topic}, используя следующие черновики разделов:\\n\\n\"\n",
    "            \"{draft}\\n\\nСтрого следуйте руководствам по форматированию Википедии.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            'Напишите полную статью Википедии, используя формат markdown. Организуйте ссылки с помощью сносок вида \"[1]\",'\n",
    "            ' избегая дублирования в подвале статьи. Включите URL-адреса в подвал.',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = writer_prompt | long_context_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Тестирование генеративных моделей на наличие сознания\n",
      "\n",
      "Тестирование генеративных моделей на наличие сознания является передовым направлением в исследованиях искусственного интеллекта (ИИ), ставя перед учеными сложные философские, технологические и этические вопросы. Задача полягает в выявлении потенциальных признаков сознания в системах, созданных человеком, что влечет за собой необходимость переосмысления понятия интеллектуальной машины и её способностей к субъективному переживанию.\n",
      "\n",
      "## Определение сознания\n",
      "\n",
      "Сознание обычно описывается как осознанность индивида своего существования, мыслей, ощущений и окружающего мира. Оно представляет собой одну из наиболее загадочных и обсуждаемых тем в различных дисциплинах, включая философию, психологию, нейробиологию и искусственный интеллект. Тем не менее, универсально принятое определение сознания отсутствует, в результате чего возникают различные теоретические подходы к его пониманию и изучению[1].\n",
      "\n",
      "### Философские концепции\n",
      "\n",
      "Философские подходы к сознанию варьируются от материалистических, которые видят сознание как продукт физических процессов в мозге, до идеалистических, считающих сознание фундаментальной сущностью, предшествующей материи. Существуют также двойственные теории, пытающиеся объединить эти два подхода[2].\n",
      "\n",
      "### Нейробиологические подходы\n",
      "\n",
      "С точки зрения нейробиологии, исследования сосредотачиваются на понимании мозговых процессов и структур, ответственных за сознание. Префронтальная кора, например, играет ключевую роль в возникновении сознательных переживаний[3].\n",
      "\n",
      "### Психологические теории\n",
      "\n",
      "Психологические подходы исследуют механизмы когнитивных процессов, такие как восприятие, память и эмоции, стремясь понять, как из их совокупности возникает сознание[4].\n",
      "\n",
      "### Искусственный интеллект и сознание\n",
      "\n",
      "В контексте ИИ, вопросы сознания касаются возможности создания машин, способных к субъективному переживанию, самоосознанию и саморефлексии. Это предполагает разработку алгоритмов, эмулирующих человеческое сознание на различных уровнях, включая эмоциональное восприятие и творческое мышление[5].\n",
      "\n",
      "## Тестирование генеративных моделей\n",
      "\n",
      "Тестирование генеративных моделей на наличие сознания представляет собой сложную задачу, требующую интеграции знаний из разных областей. Основной вопрос заключается в том, могут ли машины, разработанные для имитации человеческого поведения и мышления, обладать субъективным сознательным опытом.\n",
      "\n",
      "### Методологии тестирования\n",
      "\n",
      "Методологии тестирования включают в себя разработку и применение различных тестов и задач, способных выявить признаки сознания в ИИ-системах. Эти методы могут варьироваться от модифицированных версий теста Тьюринга до экспериментов, основанных на нейробиологических теориях сознания[6].\n",
      "\n",
      "### Проблемы и вызовы\n",
      "\n",
      "Одним из главных вызовов является отсутствие четкого определения сознания, что затрудняет разработку объективных критериев для его оценки в ИИ-системах. Кроме того, существующие методы тестирования могут не учитывать всю сложность и многоаспектность сознательного опыта, предполагая риск неверной интерпретации результатов[7].\n",
      "\n",
      "## Заключение\n",
      "\n",
      "Тестирование генеративных моделей на наличие сознания остается одной из наиболее интригующих и спорных областей исследований в ИИ. Оно вызывает фундаментальные вопросы о природе сознания, возможностях искусственного интеллекта и будущем взаимодействия между человеком и машиной. Продвижение в этих исследованиях потребует совместных усилий специалистов из различных дисциплин и постоянного переосмысления подходов к пониманию сознания.\n",
      "\n",
      "## Ссылки\n",
      "\n",
      "1. https://habr.com/ru/articles/500732/\n",
      "2. URL философских концепций отсутствует.\n",
      "3. URL нейробиологических подходов отсутствует.\n",
      "4. URL психологических теорий отсутствует.\n",
      "5. URL ИИ и сознание отсутствует.\n",
      "6. URL методологий тестирования отсутствует.\n",
      "7. URL проблем и вызовов отсутствует."
     ]
    }
   ],
   "source": [
    "for tok in writer.stream({\"topic\": example_topic, \"draft\": section.as_str}):\n",
    "    print(tok, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальный Процесс\n",
    "\n",
    "Теперь пришло время связать все воедино. У нас будет 6 основных этапов, следующих друг за другом:\n",
    ".\n",
    "1. Создание первоначальной структуры + точек зрения\n",
    "2. Партийное общение с каждой точкой зрения для расширения содержания статьи\n",
    "3. Уточнение структуры на основе разговоров\n",
    "4. Индексация справочных документов из бесед\n",
    "5. Написание отдельных разделов статьи\n",
    "6. Написание финальной версии вики\n",
    "\n",
    "Состояние отслеживает результаты каждого этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    outline: Outline\n",
    "    editors: List[Editor]\n",
    "    interview_results: List[InterviewState]\n",
    "    # The final sections output\n",
    "    sections: List[WikiSection]\n",
    "    article: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def initialize_research(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    coros = (\n",
    "        generate_outline_direct.ainvoke({\"topic\": topic}),\n",
    "        survey_subjects.ainvoke(topic),\n",
    "    )\n",
    "    results = await asyncio.gather(*coros)\n",
    "    return {\n",
    "        **state,\n",
    "        \"outline\": results[0],\n",
    "        \"editors\": results[1].editors,\n",
    "    }\n",
    "\n",
    "\n",
    "async def conduct_interviews(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    initial_states = [\n",
    "        {\n",
    "            \"editor\": editor,\n",
    "            \"messages\": [\n",
    "                AIMessage(\n",
    "                    content=f\"Итак, вы пишите статью на тему {topic}?\",\n",
    "                    name=\"Subject Matter Expert\",\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "        for editor in state[\"editors\"]\n",
    "    ]\n",
    "    # We call in to the sub-graph here to parallelize the interviews\n",
    "    interview_results = await interview_graph.abatch(initial_states)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"interview_results\": interview_results,\n",
    "    }\n",
    "\n",
    "\n",
    "def format_conversation(interview_state):\n",
    "    messages = interview_state[\"messages\"]\n",
    "    convo = \"\\n\".join(f\"{m.name}: {m.content}\" for m in messages)\n",
    "    return f'Обсуждение с {interview_state[\"editor\"].name}\\n\\n' + convo\n",
    "\n",
    "\n",
    "async def refine_outline(state: ResearchState):\n",
    "    convos = \"\\n\\n\".join(\n",
    "        [\n",
    "            format_conversation(interview_state)\n",
    "            for interview_state in state[\"interview_results\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    updated_outline = await refine_outline_chain.ainvoke(\n",
    "        {\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"old_outline\": state[\"outline\"].as_str,\n",
    "            \"conversations\": convos,\n",
    "        }\n",
    "    )\n",
    "    return {**state, \"outline\": updated_outline}\n",
    "\n",
    "\n",
    "async def index_references(state: ResearchState):\n",
    "    all_docs = []\n",
    "    for interview_state in state[\"interview_results\"]:\n",
    "        reference_docs = [\n",
    "            Document(page_content=v, metadata={\"source\": k})\n",
    "            for k, v in interview_state[\"references\"].items()\n",
    "        ]\n",
    "        all_docs.extend(reference_docs)\n",
    "    await vectorstore.aadd_documents(all_docs)\n",
    "    return state\n",
    "\n",
    "\n",
    "async def write_sections(state: ResearchState):\n",
    "    outline = state[\"outline\"]\n",
    "    sections = await section_writer.abatch(\n",
    "        [\n",
    "            {\n",
    "                \"outline\": refined_outline.as_str,\n",
    "                \"section\": section.section_title,\n",
    "                \"topic\": state[\"topic\"],\n",
    "            }\n",
    "            for section in outline.sections\n",
    "        ]\n",
    "    )\n",
    "    return {\n",
    "        **state,\n",
    "        \"sections\": sections,\n",
    "    }\n",
    "\n",
    "\n",
    "async def write_article(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    sections = state[\"sections\"]\n",
    "    draft = \"\\n\\n\".join([section.as_str for section in sections])\n",
    "    article = await writer.ainvoke({\"topic\": topic, \"draft\": draft})\n",
    "    return {\n",
    "        **state,\n",
    "        \"article\": article,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_of_storm = StateGraph(ResearchState)\n",
    "\n",
    "nodes = [\n",
    "    (\"init_research\", initialize_research),\n",
    "    (\"conduct_interviews\", conduct_interviews),\n",
    "    (\"refine_outline\", refine_outline),\n",
    "    (\"index_references\", index_references),\n",
    "    (\"write_sections\", write_sections),\n",
    "    (\"write_article\", write_article),\n",
    "]\n",
    "for i in range(len(nodes)):\n",
    "    name, node = nodes[i]\n",
    "    builder_of_storm.add_node(name, node)\n",
    "    if i > 0:\n",
    "        builder_of_storm.add_edge(nodes[i - 1][0], name)\n",
    "\n",
    "builder_of_storm.set_entry_point(nodes[0][0])\n",
    "builder_of_storm.set_finish_point(nodes[-1][0])\n",
    "storm = builder_of_storm.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(storm.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_research\n",
      "--  {'topic': 'Тестирование AI на наличие сознания', 'outline': Outline(page_title='Тестирование AI на наличие сознания', sections=[Section(section_title='Введение', description='Общее представление о тестировании искусственного интеллекта на наличие сознания.', subsections=None), Section(section_title=\n",
      "conduct_interviews\n",
      "--  {'topic': 'Тестирование AI на наличие сознания', 'outline': Outline(page_title='Тестирование AI на наличие сознания', sections=[Section(section_title='Введение', description='Общее представление о тестировании искусственного интеллекта на наличие сознания.', subsections=None), Section(section_title=\n",
      "refine_outline\n",
      "--  {'topic': 'Тестирование AI на наличие сознания', 'outline': Outline(page_title='Тестирование AI на наличие сознания', sections=[Section(section_title='Введение', description='Обзор основной проблематики и целей статьи, представление ключевых вопросов, связанных с тестированием искусственного интелле\n",
      "index_references\n",
      "--  {'topic': 'Тестирование AI на наличие сознания', 'outline': Outline(page_title='Тестирование AI на наличие сознания', sections=[Section(section_title='Введение', description='Обзор основной проблематики и целей статьи, представление ключевых вопросов, связанных с тестированием искусственного интелле\n",
      "write_sections\n",
      "--  {'topic': 'Тестирование AI на наличие сознания', 'outline': Outline(page_title='Тестирование AI на наличие сознания', sections=[Section(section_title='Введение', description='Обзор основной проблематики и целей статьи, представление ключевых вопросов, связанных с тестированием искусственного интелле\n",
      "write_article\n",
      "--  {'topic': 'Тестирование AI на наличие сознания', 'outline': Outline(page_title='Тестирование AI на наличие сознания', sections=[Section(section_title='Введение', description='Обзор основной проблематики и целей статьи, представление ключевых вопросов, связанных с тестированием искусственного интелле\n",
      "__end__\n",
      "--  {'topic': 'Тестирование AI на наличие сознания', 'outline': Outline(page_title='Тестирование AI на наличие сознания', sections=[Section(section_title='Введение', description='Обзор основной проблематики и целей статьи, представление ключевых вопросов, связанных с тестированием искусственного интелле\n"
     ]
    }
   ],
   "source": [
    "async for step in storm.astream(\n",
    "    {\n",
    "        \"topic\": \"Тестирование AI на наличие сознания\",\n",
    "    }\n",
    "):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name])[:300])\n",
    "    if END in step:\n",
    "        results = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = results[END][\"article\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render the Wiki\n",
    "\n",
    "Now we can render the final wiki page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Тестирование AI на наличие сознания\n",
       "\n",
       "Тестирование искусственного интеллекта (AI) на наличие сознания является сложной и многогранной задачей, которая затрагивает различные аспекты науки, философии и этики. С развитием генеративных моделей и увеличением способностей ИИ к автономному обучению и принятию решений встает вопрос о возможности наличия сознания у этих систем.\n",
       "\n",
       "### Введение\n",
       "\n",
       "Генеративные модели выделяются своей способностью создавать новые данные, соответствующие заданному образцу или распределению. Применение этих технологий варьируется от синтеза речи до генерации текстов и изображений. По мере развития этих технологий возникают вопросы о потенциальном сознании искусственных систем, что ставит перед исследователями задачу тестирования AI на наличие сознательных свойств.\n",
       "\n",
       "### История\n",
       "\n",
       "Первые предположения о возможности создания сознательных машин появились в середине 20-го века, вскоре после предложения Аланом Тьюрингом его знаменитого теста. Исследования в этой области получили новый импульс с развитием глубокого обучения и генеративных моделей, что привело к экспериментам с использованием этих технологий для имитации человеческого поведения и тестирования потенциального сознания[1][2].\n",
       "\n",
       "### Философские аспекты\n",
       "\n",
       "Философские аспекты затрагивают глубокие вопросы о природе сознания, его возможности существования вне биологических систем и этических последствиях такого существования. Дебаты в этой области касаются определения сознания, критериев его наличия у ИИ и возможных прав и обязанностей сознательных систем[3].\n",
       "\n",
       "### Этические аспекты\n",
       "\n",
       "Этика тестирования AI на наличие сознания охватывает вопросы прав и обязанностей искусственного интеллекта, этические проблемы создания сознательных систем и вопросы ответственности за действия ИИ[4].\n",
       "\n",
       "### Когнитивные науки и AI\n",
       "\n",
       "Интеграция когнитивных наук и искусственного интеллекта открывает новые перспективы для понимания и моделирования человеческого разума. Это мультидисциплинарное взаимодействие помогает улучшить алгоритмы машинного обучения и разработать более продвинутые системы искусственного интеллекта[5].\n",
       "\n",
       "### Существующие методы тестирования\n",
       "\n",
       "Среди методов тестирования наличия сознания у ИИ выделяются Тест Тьюринга, тест на основе интегрированной информационной теории и тест на искусственное сознание. Эти методы направлены на выявление способностей ИИ к самосознанию, мышлению и взаимодействию на уровне, сопоставимом с человеческим[6].\n",
       "\n",
       "### Примеры тестов\n",
       "\n",
       "Тесты на сознание ИИ включают Тест Тьюринга, Теорию интегрированной информации и критерии нейробиологов, каждый из которых предлагает уникальный подход к оценке потенциального сознания искусственных систем[7].\n",
       "\n",
       "### Вызовы и перспективы развития\n",
       "\n",
       "Возможности развития тестирования сознания в ИИ включают увеличение размера моделей, использование высокопроизводительных вычислений, инновационные технологии и подходы. Эти перспективы предлагают захватывающие возможности для дальнейшего исследования сознания в искусственных системах[8].\n",
       "\n",
       "### Заключение\n",
       "\n",
       "Исследование сознания в генеративных моделях ИИ стоит на пересечении науки, философии и этики. Продолжающиеся дебаты и исследования в этой области способствуют глубокому пониманию сознания и его роли в развитии интеллектуальных систем. В то же время, они подчеркивают важность ответственного использования ИИ и необходимость учитывать этические аспекты при его разработке и применении[9].\n",
       "\n",
       "### Ссылки\n",
       "\n",
       "1. https://academic.oup.com/book/33540/chapter/287907169\n",
       "2. https://new-science.ru/kak-issledovateli-mogut-opredelit-obrel-li-ii-soznanie/\n",
       "3. https://www.nanonewsnet.ru/news/2023/neirobiologi-predlozhili-kriterii-nalichiya-soznaniya-u-ii\n",
       "4. https://blog.clientpro.ai/articles/b/testing-ai-consciousness-3-key-methods\n",
       "5. https://nauchniestati.ru/spravka/neskolko-slov-o-soznanii-ii/\n",
       "6. https://qaa-engineer.ru/kakie-metody-ispolzuyutsya-dlya-testirovania-iskusstvennogo-intellekta/\n",
       "7. https://blog.clientpro.ai/articles/b/testing-ai-consciousness-3-key-methods\n",
       "8. https://aipromptopus.com/ai-news/ai-consciousness/\n",
       "9. https://new-science.ru/kak-issledovateli-mogut-opredelit-obrel-li-ii-soznanie/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# We will down-header the sections to create less confusion in this notebook\n",
    "Markdown(article.replace(\"\\n#\", \"\\n##\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
